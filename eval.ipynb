{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer,BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = BertForSequenceClassification.from_pretrained('./fine_tuned_bert_sentiment')\n",
    "test_tokenizer = BertTokenizer.from_pretrained('./fine_tuned_bert_sentiment')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment\n",
    "def predict_sentiment(text):\n",
    "    inputs = test_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    # Move input tensors to the same device as the model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = test_model(**inputs)\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    return \"Positive\" if probabilities[0][1] > probabilities[0][0] else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now, let's try with your own input!\n",
      "\n",
      "Your review:\n",
      "================================================================================\n",
      "If you love dining in near darkness and squinting at a menu, The Gourmet Shack\n",
      "is for you! The mismatched furniture adds that \"we tried\" vibe, and the service?\n",
      "Practically invisible—until they swoop in like ninjas with your food.  Speaking\n",
      "of the food, each dish looks like modern art—tiny portions that leave you\n",
      "wondering if you've actually eaten anything. But hey, it's surprisingly\n",
      "delicious. And the dessert? Perfectly sized for ants.  So, if you're into paying\n",
      "for confusion and unexpectedly great flavors, this is the place for you!\n",
      "================================================================================\n",
      "\n",
      "Predicted sentiment for your review: Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and move model to GPU if possible\n",
    "import textwrap\n",
    "\n",
    "test_model = test_model.to(device)\n",
    "\n",
    "\n",
    "print(\"\\nNow, let's try with your own input!\")\n",
    "user_review = input(\"Enter a restaurant review: \")\n",
    "user_sentiment = predict_sentiment(user_review)\n",
    "\n",
    "prettified_review = textwrap.fill(user_review, width=80)\n",
    "# print(f'\\nYour review: {user_review}')\n",
    "print(f\"\\nYour review:\\n{'='*80}\\n{prettified_review}\\n{'='*80}\")\n",
    "print(f\"\\nPredicted sentiment for your review: {user_sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
